{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part2. Compare Taste Predictors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hy/Documents/Project/bitterants/\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "PWD = os.path.abspath('.')+'/'\n",
    "print(PWD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_train_path = os.path.join(PWD, 'dataset/taste_dataset/bitter_sweet/bs_train.csv')\n",
    "bn_train_path = os.path.join(PWD, 'dataset/taste_dataset/bitter_nonbitter/bn_train.csv')\n",
    "bs_test_path = os.path.join(PWD, 'dataset/taste_dataset/bitter_sweet/bs_test.csv')\n",
    "bn_test_path = os.path.join(PWD, 'dataset/taste_dataset/bitter_nonbitter/bn_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train other predictors -- 1. CNN and MLP in https://www.sciencedirect.com/science/article/pii/S096399692200031X#f0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6149703492136562 ACC: 0.6816810640340051 AUC: 0.6412951068366473\n",
      "loss: 0.5668444037437439 ACC: 0.7080899492664197 AUC: 0.6761815896176262\n",
      "loss: 0.5040962590890772 ACC: 0.7534896476072946 AUC: 0.7188550490269546\n",
      "loss: 0.4366242570035598 ACC: 0.7955710955710957 AUC: 0.7744626481852404\n",
      "loss: 0.39052246423328624 ACC: 0.8273961332784863 AUC: 0.815698222207054\n",
      "loss: 0.32721036321976604 ACC: 0.8589195118606885 AUC: 0.8471779072241037\n",
      "loss: 0.26861845307490406 ACC: 0.8932949403537641 AUC: 0.8811212261181662\n",
      "loss: 0.2528698277824065 ACC: 0.9055121349238998 AUC: 0.8950606732539194\n",
      "loss: 0.17065640538930893 ACC: 0.9351432880844647 AUC: 0.929697514912665\n",
      "Early stopping\n",
      "5701\n",
      "loss: 0.6086662411689758 ACC: 0.6962656972901522 AUC: 0.6823065735769941\n",
      "loss: 0.622581190922681 ACC: 0.655056179775281 AUC: 0.6493734486821753\n",
      "loss: 0.5256393621949589 ACC: 0.7407138136153338 AUC: 0.7296872714191608\n",
      "loss: 0.523124650997274 ACC: 0.7477858559153999 AUC: 0.7326908769746399\n",
      "loss: 0.4154482992256389 ACC: 0.80783212161269 AUC: 0.8050726311024229\n",
      "loss: 0.33168097629266624 ACC: 0.8626900198281561 AUC: 0.8580150634021014\n",
      "loss: 0.28037869754959555 ACC: 0.8899537343027099 AUC: 0.8856456619833443\n",
      "loss: 0.2842121334636913 ACC: 0.8862855254461334 AUC: 0.8869213687648706\n",
      "Early stopping\n",
      "loss: 0.7171096170649809 ACC: 0.5993212669683258 AUC: 0.574259005556469\n",
      "loss: 0.5810007382841671 ACC: 0.6866515837104072 AUC: 0.6603884926911583\n",
      "loss: 0.5859268377808964 ACC: 0.671342383107089 AUC: 0.665607355334383\n",
      "loss: 0.5339908196645624 ACC: 0.7075414781297135 AUC: 0.700777820161279\n",
      "loss: 0.5208542820285348 ACC: 0.7204374057315233 AUC: 0.7052476493285793\n",
      "loss: 0.49741000112365275 ACC: 0.7665912518853695 AUC: 0.7548110166882931\n",
      "Early stopping\n",
      "loss: 0.8960842945996452 ACC: 0.5944950750253153 AUC: 0.5937573944606847\n",
      "loss: 0.6116529422647813 ACC: 0.6668047500690417 AUC: 0.6604125986076179\n",
      "loss: 0.6087975046213936 ACC: 0.6463684065175366 AUC: 0.6429284244445903\n",
      "Early stopping\n",
      "loss: 0.2041642740368843 ACC: 0.9204374057315234 AUC: 0.9159792750000035\n",
      "loss: 0.13218185316552133 ACC: 0.9513574660633483 AUC: 0.9481474175207961\n",
      "loss: 0.10668919870958608 ACC: 0.9581447963800904 AUC: 0.9565885087539532\n",
      "loss: 0.06706257022725527 ACC: 0.9724736048265458 AUC: 0.9705811185410181\n",
      "loss: 0.05348594405222684 ACC: 0.9777526395173455 AUC: 0.9770083204204731\n",
      "Early stopping\n",
      "loss: 0.1595354544765809 ACC: 0.9371260241185676 AUC: 0.9348794246855978\n",
      "loss: 0.08013441293116878 ACC: 0.9701739850869927 AUC: 0.9693663605384757\n",
      "loss: 0.06820683707209195 ACC: 0.9726594863297431 AUC: 0.9709456644227148\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from hgnn.trainers import train_mlp_cnn\n",
    "from contrast_predictors.CNN import *\n",
    "from contrast_predictors.MLP import *\n",
    "\n",
    "bs_train = loader(bs_train_path) \n",
    "bn_train = loader(bn_train_path) \n",
    "bs_test = loader(bs_test_path) \n",
    "bn_test = loader(bn_test_path) \n",
    "\n",
    "\n",
    "model = BoCNN()\n",
    "bn_train_imgs_dir = os.path.join(PWD, 'dataset/taste_dataset/bitter_nonbitter/bn_train_imgs/') \n",
    "if not os.path.exists(bn_train_imgs_dir):\n",
    "    os.mkdir(bn_train_imgs_dir)\n",
    "bn_cnn_train = cnn_prepare(bn_train, bn_train_imgs_dir, data_aug=True)\n",
    "all = all_batchsize(bn_cnn_train, batchsize=int(len(bn_cnn_train)/16))\n",
    "train_mlp_cnn.train_bi_classify_all(model, all=all, max_epochs=500, patience=7, save_folder=PWD+'/pretrained/', save_name='bn_cnn.pth',)\n",
    "\n",
    "model = BoCNN()\n",
    "bs_train_imgs_dir = os.path.join(PWD, 'dataset/taste_dataset/bitter_sweet/bs_train_imgs/') \n",
    "if not os.path.exists(bs_train_imgs_dir):\n",
    "    os.mkdir(bs_train_imgs_dir)\n",
    "bs_cnn_train = cnn_prepare(bs_train, bs_train_imgs_dir, data_aug=True)\n",
    "print(len(bs_cnn_train))\n",
    "all = all_batchsize(bs_cnn_train, batchsize=int(len(bs_cnn_train)/16))\n",
    "train_mlp_cnn.train_bi_classify_all(model, all=all, max_epochs=500, patience=7, save_folder=PWD+'/pretrained/', save_name='bs_cnn.pth',)\n",
    "\n",
    "bn_ds_mlp_train = Descriptors_bitter_nonbitter(bn_train)\n",
    "all = all_batchsize(bn_ds_mlp_train, batchsize=int(len(bn_ds_mlp_train)/16))\n",
    "model = BoMLP(n_feats=21)\n",
    "train_mlp_cnn.train_bi_classify_all(model, all=all, max_epochs=500, patience=7, save_folder=PWD+'/pretrained/', save_name='bn_ds_mlp.pth')\n",
    "\n",
    "\n",
    "bs_ds_mlp_train = Descriptors_bitter_sweet(bs_train)\n",
    "all = all_batchsize(bs_ds_mlp_train, batchsize=int(len(bs_ds_mlp_train)/16))\n",
    "model = BoMLP(n_feats=17)\n",
    "train_mlp_cnn.train_bi_classify_all(model, all=all, max_epochs=500, patience=7, save_folder=PWD+'/pretrained/', save_name='bs_ds_mlp.pth')\n",
    "\n",
    "\n",
    "bn_rdkfp_mlp_train = RDKFP(bn_train)\n",
    "all = all_batchsize(bn_rdkfp_mlp_train, batchsize=int(len(bn_rdkfp_mlp_train)/16))\n",
    "model = BoMLP(n_feats=2048)\n",
    "train_mlp_cnn.train_bi_classify_all(model, all=all, max_epochs=500, patience=7, save_folder=PWD+'/pretrained/', save_name='bn_rdkfp_mlp.pth')\n",
    "\n",
    "\n",
    "bs_rdkfp_mlp_train = RDKFP(bs_train)\n",
    "all = all_batchsize(bs_rdkfp_mlp_train, batchsize=int(len(bs_rdkfp_mlp_train)/16))\n",
    "model = BoMLP(n_feats=2048)\n",
    "train_mlp_cnn.train_bi_classify_all(model, all=all, max_epochs=500, patience=7, save_folder=PWD+'/pretrained/', save_name='bs_rdkfp_mlp.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train other predictors -- 2. BitterPredict (Adapt Boost)  in https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5608695/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from contrast_predictors.BitterPredict import *\n",
    "from hgnn.utils import bi_classify_metrics\n",
    "\n",
    "qikprop_filepath = os.path.join(PWD+\"/dataset/taste_dataset/qikprop.CSV\") \n",
    "AdaBoost.train(bn_train_path, qikprop_filepath, \"bn_Adaboost\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### train this study predictors -- 3. gnns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hy/Softwares/Program/miniconda3/envs/ml/lib/python3.8/site-packages/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6815344025106991 ACC: 0.6130467571644042 AUC: 0.5473659942325813\n",
      "loss: 0.6384974051924313 ACC: 0.6417043740573152 AUC: 0.6127841298996419\n",
      "loss: 0.6564112235518063 ACC: 0.6414781297134238 AUC: 0.6301215838370949\n",
      "loss: 0.6489547456012053 ACC: 0.6296380090497737 AUC: 0.5854862605484447\n",
      "loss: 0.6146537100567537 ACC: 0.6719457013574661 AUC: 0.6337969461099802\n",
      "loss: 0.6235239646014046 ACC: 0.6601055806938159 AUC: 0.6328310197777924\n",
      "loss: 0.5655158968532786 ACC: 0.7181749622926092 AUC: 0.6977843418409581\n",
      "loss: 0.5266627730692134 ACC: 0.7499999999999998 AUC: 0.7333608723684465\n",
      "loss: 0.4933238976141986 ACC: 0.782051282051282 AUC: 0.7610712616458644\n",
      "loss: 0.5160002901273615 ACC: 0.7660633484162895 AUC: 0.7595965894205703\n",
      "loss: 0.5117454791770262 ACC: 0.7547511312217194 AUC: 0.7518215849085687\n",
      "loss: 0.5023986048558179 ACC: 0.779713423831071 AUC: 0.7641875124918304\n",
      "loss: 0.4898134575170629 ACC: 0.7803167420814479 AUC: 0.7735145187419715\n",
      "loss: 0.46182912763427286 ACC: 0.794419306184012 AUC: 0.7877912077925818\n",
      "loss: 0.48132292663349824 ACC: 0.8005279034690799 AUC: 0.784109096499704\n",
      "loss: 0.41949455527698293 ACC: 0.8144796380090498 AUC: 0.8006382332429319\n",
      "loss: 0.4424418859622058 ACC: 0.7909502262443439 AUC: 0.7831956559847884\n",
      "loss: 0.41916777105892405 ACC: 0.813348416289593 AUC: 0.8039491277284134\n",
      "loss: 0.439616438220529 ACC: 0.8015082956259428 AUC: 0.7889226457049041\n",
      "loss: 0.4005954773987041 ACC: 0.8211915535444948 AUC: 0.8121123438219271\n",
      "loss: 0.38688048019128685 ACC: 0.8344645550527904 AUC: 0.8223028224356626\n",
      "loss: 0.3762586673392969 ACC: 0.8340874811463046 AUC: 0.8239804735174785\n",
      "loss: 0.36572818019810843 ACC: 0.8472850678733033 AUC: 0.8359187025767761\n",
      "loss: 0.3688366500770344 ACC: 0.8355203619909501 AUC: 0.8225796260846577\n",
      "loss: 0.3969800945590524 ACC: 0.8352187028657618 AUC: 0.8288807412319796\n",
      "loss: 0.3764934434610255 ACC: 0.8340120663650076 AUC: 0.80534233836467\n",
      "loss: 0.3596979476073209 ACC: 0.8453996983408747 AUC: 0.8349993582207436\n",
      "loss: 0.39232054177452536 ACC: 0.8248868778280543 AUC: 0.8130031084692783\n",
      "loss: 0.3703566675677019 ACC: 0.8423831070889893 AUC: 0.8328781565458281\n",
      "loss: 0.3512093749116449 ACC: 0.8499245852187028 AUC: 0.8383578403109588\n",
      "loss: 0.3412457055905286 ACC: 0.8539969834087482 AUC: 0.846930651385475\n",
      "loss: 0.34980303925626416 ACC: 0.8449472096530919 AUC: 0.8380228594476811\n",
      "loss: 0.3830467585255118 ACC: 0.8339366515837103 AUC: 0.8193717892637113\n",
      "loss: 0.3484283405191758 ACC: 0.839291101055807 AUC: 0.8110931799373078\n",
      "loss: 0.34172505447093177 ACC: 0.853318250377074 AUC: 0.8424332091980892\n",
      "loss: 0.32152576832210317 ACC: 0.8582202111613875 AUC: 0.848699610713984\n",
      "loss: 0.3382721280350405 ACC: 0.8448717948717948 AUC: 0.8405837799241099\n",
      "loss: 0.40230393059113445 ACC: 0.8169683257918551 AUC: 0.8124448594574959\n",
      "loss: 0.38980647220331077 ACC: 0.8415535444947211 AUC: 0.835883836946335\n",
      "loss: 0.3412151371731478 ACC: 0.8563348416289592 AUC: 0.8454671508997357\n",
      "loss: 0.32183877773144665 ACC: 0.866892911010558 AUC: 0.8552081566178539\n",
      "loss: 0.35568515956401825 ACC: 0.8376319758672702 AUC: 0.8283243955364868\n",
      "loss: 0.3778422562515034 ACC: 0.8237556561085972 AUC: 0.8100231044515508\n",
      "Early stopping\n",
      "loss: 0.6576588294085335 ACC: 0.6432880844645551 AUC: 0.6116785879553588\n",
      "loss: 0.5918985394870534 ACC: 0.6838612368024135 AUC: 0.649139649099927\n",
      "loss: 0.594420916893903 ACC: 0.7064856711915536 AUC: 0.6934718000208201\n",
      "loss: 0.5615864238318276 ACC: 0.7250377073906487 AUC: 0.7060894236907778\n",
      "loss: 0.5397951532812679 ACC: 0.7272247360482654 AUC: 0.705090952775638\n",
      "loss: 0.5766968516742482 ACC: 0.715686274509804 AUC: 0.6852315623701264\n",
      "loss: 0.5206550938241622 ACC: 0.7544494720965309 AUC: 0.723358849528986\n",
      "loss: 0.48749011754989624 ACC: 0.7676470588235295 AUC: 0.7478621531122842\n",
      "loss: 0.48404177146799426 ACC: 0.7785822021116139 AUC: 0.7651022276831482\n",
      "loss: 0.49828894524013295 ACC: 0.7527149321266967 AUC: 0.7359487901431305\n",
      "loss: 0.4670671943356009 ACC: 0.7933634992458523 AUC: 0.778886988006462\n",
      "loss: 0.42400578891529755 ACC: 0.8113876319758674 AUC: 0.7960264110897748\n",
      "loss: 0.4039089469348683 ACC: 0.8101809954751131 AUC: 0.7925900675360682\n",
      "loss: 0.42038314307437225 ACC: 0.8113122171945703 AUC: 0.7979446912155523\n",
      "loss: 0.3885826380813823 ACC: 0.8264705882352942 AUC: 0.8135473886039178\n",
      "loss: 0.40424535029074726 ACC: 0.8261689291101056 AUC: 0.804632960404069\n",
      "loss: 0.3682738533791374 ACC: 0.8382352941176471 AUC: 0.8227270218250561\n",
      "loss: 0.35425957599106955 ACC: 0.8475867269984918 AUC: 0.8353725510696812\n",
      "loss: 0.3279995604911271 ACC: 0.852187028657617 AUC: 0.8402105446870438\n",
      "loss: 0.3466576074852663 ACC: 0.8365761689291101 AUC: 0.8363539227900447\n",
      "loss: 0.42278625334010406 ACC: 0.8007541478129712 AUC: 0.7900272006556307\n",
      "loss: 0.3592551911578459 ACC: 0.8370286576168929 AUC: 0.8274424371517819\n",
      "loss: 0.32801930518711314 ACC: 0.8506787330316741 AUC: 0.8377987147919963\n",
      "loss: 0.3030499300974257 ACC: 0.8684012066365006 AUC: 0.8603809654581822\n",
      "loss: 0.32662783300175385 ACC: 0.8709653092006036 AUC: 0.8664518798352926\n",
      "loss: 0.35181409997098584 ACC: 0.839969834087481 AUC: 0.8242403817737756\n",
      "loss: 0.3156457972877166 ACC: 0.8503016591251885 AUC: 0.8399813909798637\n",
      "loss: 0.29660266550148234 ACC: 0.8596530920060331 AUC: 0.8325221954109628\n",
      "loss: 0.2905993303831886 ACC: 0.874811463046757 AUC: 0.8675951699584832\n",
      "loss: 0.2708371465697008 ACC: 0.8876319758672699 AUC: 0.877712453037544\n",
      "loss: 0.24968793418477564 ACC: 0.8921568627450981 AUC: 0.8829338426195887\n",
      "loss: 0.25181098808260527 ACC: 0.8935897435897437 AUC: 0.8890095135105696\n",
      "loss: 0.26619503559435115 ACC: 0.8880090497737557 AUC: 0.8734694289423407\n",
      "loss: 0.2511740265523686 ACC: 0.8978129713423831 AUC: 0.8900592839963357\n",
      "loss: 0.23870322195922627 ACC: 0.9034690799396683 AUC: 0.896681672374676\n",
      "loss: 0.25128792576930103 ACC: 0.8886877828054298 AUC: 0.8861152666551388\n",
      "loss: 0.24681937738376505 ACC: 0.8993212669683258 AUC: 0.8892056659076291\n",
      "loss: 0.2590101501520942 ACC: 0.8822021116138763 AUC: 0.8832432777566505\n",
      "loss: 0.323809011017575 ACC: 0.8600301659125189 AUC: 0.851256767162414\n",
      "loss: 0.2882934691494002 ACC: 0.8755656108597284 AUC: 0.8621651381146357\n",
      "loss: 0.2624294415992849 ACC: 0.8890648567119155 AUC: 0.8791145939583223\n",
      "loss: 0.25334931734730215 ACC: 0.8834087481146305 AUC: 0.8561437317444954\n",
      "Early stopping\n",
      "loss: 0.6672604399568894 ACC: 0.5947963800904977 AUC: 0.5400490330060824\n",
      "loss: 0.6220849471933702 ACC: 0.658974358974359 AUC: 0.6274589442563296\n",
      "loss: 0.5914920919081744 ACC: 0.7009803921568627 AUC: 0.6743211121077367\n",
      "loss: 0.6064133819411782 ACC: 0.6963046757164405 AUC: 0.6698576729892247\n",
      "loss: 0.590824709219091 ACC: 0.6837858220211162 AUC: 0.6679653743715099\n",
      "loss: 0.5413608621148502 ACC: 0.7260935143288085 AUC: 0.7040876619329254\n",
      "loss: 0.5110287876690135 ACC: 0.7475867269984917 AUC: 0.7316245107517618\n",
      "loss: 0.5080469005248126 ACC: 0.7450980392156863 AUC: 0.7259834255364087\n",
      "loss: 0.4750378464951235 ACC: 0.7770739064856713 AUC: 0.7627206256310793\n",
      "loss: 0.491598318604862 ACC: 0.7610859728506787 AUC: 0.7465192643726417\n",
      "loss: 0.47883207482450146 ACC: 0.7846153846153846 AUC: 0.7698606273029224\n",
      "loss: 0.4667303071302526 ACC: 0.7792609351432883 AUC: 0.7588183184649643\n",
      "loss: 0.44101350623018604 ACC: 0.8076923076923076 AUC: 0.7917986922869573\n",
      "loss: 0.4577679686686572 ACC: 0.7909502262443439 AUC: 0.782814047269109\n",
      "loss: 0.45630404879065123 ACC: 0.804977375565611 AUC: 0.7921411363905366\n",
      "loss: 0.4286893991863026 ACC: 0.8193061840120665 AUC: 0.7970330976404156\n",
      "loss: 0.40639915536431703 ACC: 0.822398190045249 AUC: 0.8057410735728451\n",
      "loss: 0.4043388445587719 ACC: 0.8167420814479637 AUC: 0.7973576955196708\n",
      "loss: 0.41237063267651725 ACC: 0.8105580693815988 AUC: 0.7993051061877237\n",
      "loss: 0.4300399720668793 ACC: 0.8041478129713424 AUC: 0.7881040740262305\n",
      "loss: 0.40984947891796336 ACC: 0.8094268476621417 AUC: 0.7970603811690369\n",
      "loss: 0.4163299378226785 ACC: 0.8219457013574663 AUC: 0.8093729266714406\n",
      "loss: 0.37543199605801525 ACC: 0.8337104072398192 AUC: 0.8190171834699942\n",
      "loss: 0.3807901196620044 ACC: 0.8276018099547511 AUC: 0.809219652910053\n",
      "loss: 0.40041018584195304 ACC: 0.8211915535444949 AUC: 0.811537087720524\n",
      "loss: 0.37119541448705334 ACC: 0.8404977375565612 AUC: 0.8287452902750087\n",
      "loss: 0.3505395160001867 ACC: 0.8385369532428356 AUC: 0.8279280453306693\n",
      "loss: 0.34462953753331127 ACC: 0.8563348416289591 AUC: 0.840832922916197\n",
      "loss: 0.35231897760840025 ACC: 0.8411764705882353 AUC: 0.8356400345340013\n",
      "loss: 0.3355702446664081 ACC: 0.8472850678733033 AUC: 0.8339725257551779\n",
      "loss: 0.33001959411536946 ACC: 0.8634992458521871 AUC: 0.8510390893742366\n",
      "loss: 0.3490731470725116 ACC: 0.8384615384615383 AUC: 0.8248104726489648\n",
      "loss: 0.32490845813470726 ACC: 0.8672699849170438 AUC: 0.8543147755020485\n",
      "loss: 0.3164554510046454 ACC: 0.8744343891402716 AUC: 0.8635946638121906\n",
      "loss: 0.3415969101821675 ACC: 0.8501508295625941 AUC: 0.8334877121404621\n",
      "loss: 0.3345160571967854 ACC: 0.8585972850678734 AUC: 0.8500106360003724\n",
      "loss: 0.38498083677361994 ACC: 0.8174962292609351 AUC: 0.8041601112538389\n",
      "loss: 0.3511405744973351 ACC: 0.8388386123680242 AUC: 0.8267229068055433\n",
      "loss: 0.3394436792415731 ACC: 0.8616138763197586 AUC: 0.8465910070733171\n",
      "loss: 0.33283789718852325 ACC: 0.858521870286576 AUC: 0.8457028415016979\n",
      "loss: 0.33120475183514986 ACC: 0.8539969834087481 AUC: 0.8374880173934658\n",
      "Early stopping\n",
      "loss: 0.785455708994585 ACC: 0.5867269984917043 AUC: 0.5628809057247608\n",
      "loss: 0.6145847580012154 ACC: 0.6626696832579185 AUC: 0.6343810585148335\n",
      "loss: 0.5813735232633703 ACC: 0.6789592760180996 AUC: 0.6479085414327764\n",
      "loss: 0.5600895688814276 ACC: 0.7131975867269985 AUC: 0.6882537629630575\n",
      "loss: 0.5146676898002625 ACC: 0.7541478129713425 AUC: 0.7311697685513001\n",
      "loss: 0.5479671218815971 ACC: 0.7242081447963803 AUC: 0.7082056187942928\n",
      "loss: 0.4820222714368035 ACC: 0.7884615384615385 AUC: 0.770772790674715\n",
      "loss: 0.48278700604158287 ACC: 0.7725490196078433 AUC: 0.7611877957710866\n",
      "loss: 0.4704156640697928 ACC: 0.7796380090497739 AUC: 0.7589813006062801\n",
      "loss: 0.43637730268871083 ACC: 0.7944193061840122 AUC: 0.7812895845967553\n",
      "loss: 0.42198162219103647 ACC: 0.806108597285068 AUC: 0.7917588782312599\n",
      "loss: 0.43355589579133424 ACC: 0.7905731523378582 AUC: 0.7855508804036491\n",
      "loss: 0.43270203646491556 ACC: 0.7996229260935144 AUC: 0.771636656565138\n",
      "loss: 0.39048738251714143 ACC: 0.835972850678733 AUC: 0.8240681953360811\n",
      "loss: 0.3900132354568033 ACC: 0.8284313725490196 AUC: 0.8184253094691342\n",
      "loss: 0.37301379705176635 ACC: 0.8318250377073908 AUC: 0.8242183019335755\n",
      "loss: 0.40606402474291187 ACC: 0.8181749622926094 AUC: 0.8089607714255879\n",
      "loss: 0.39505133208106546 ACC: 0.8155354449472096 AUC: 0.81018737429761\n",
      "loss: 0.3671197225065792 ACC: 0.8381598793363499 AUC: 0.8091619127820026\n",
      "loss: 0.35457147920832915 ACC: 0.8540723981900454 AUC: 0.8444943705922416\n",
      "loss: 0.3692946819698109 ACC: 0.8331825037707389 AUC: 0.8293000153835713\n",
      "loss: 0.35515055498656106 ACC: 0.8450226244343892 AUC: 0.8335240025358223\n",
      "loss: 0.36998625713236194 ACC: 0.8524886877828056 AUC: 0.8432289804942105\n",
      "loss: 0.40591444863992576 ACC: 0.8286576168929111 AUC: 0.8193457741620287\n",
      "loss: 0.3702709867673762 ACC: 0.8378582202111613 AUC: 0.8257629050072496\n",
      "loss: 0.3274633792393348 ACC: 0.8578431372549019 AUC: 0.8466683141560586\n",
      "loss: 0.3336747639319476 ACC: 0.8638763197586727 AUC: 0.8538784033384735\n",
      "loss: 0.3250326198690078 ACC: 0.8582202111613875 AUC: 0.8456770938134583\n",
      "loss: 0.31855352310573354 ACC: 0.8634992458521871 AUC: 0.8513324326095676\n",
      "loss: 0.30652955525061665 ACC: 0.8774509803921569 AUC: 0.8690956674302734\n",
      "loss: 0.3231920862899107 ACC: 0.8649321266968326 AUC: 0.8592663995346933\n",
      "loss: 0.3084973885732539 ACC: 0.8729260935143287 AUC: 0.8649736025804508\n",
      "loss: 0.3623380731133854 ACC: 0.8457767722473605 AUC: 0.8340955054248795\n",
      "loss: 0.34211498674224405 ACC: 0.8616138763197588 AUC: 0.8502550963158891\n",
      "loss: 0.34729432796730714 ACC: 0.8514328808446455 AUC: 0.8352362651050428\n",
      "loss: 0.3208824799341314 ACC: 0.8550527903469081 AUC: 0.8519398809265004\n",
      "loss: 0.3310532447169809 ACC: 0.8627450980392155 AUC: 0.8574485749661821\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hy/Softwares/Program/miniconda3/envs/ml/lib/python3.8/site-packages/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6960928510217106 ACC: 0.5039583908680842 AUC: 0.49788787101938636\n",
      "loss: 0.6474724376902861 ACC: 0.616266224799779 AUC: 0.6299315005075864\n",
      "loss: 0.6110008078462937 ACC: 0.6859523151983797 AUC: 0.6816407044161599\n",
      "loss: 0.5670797193751616 ACC: 0.7226364724293475 AUC: 0.7155764185075516\n",
      "loss: 0.5445483414565816 ACC: 0.7316579213845162 AUC: 0.722517232827621\n",
      "loss: 0.5186884017551646 ACC: 0.7508054865138545 AUC: 0.7497951473284459\n",
      "loss: 0.5171804673531476 ACC: 0.7698609960416092 AUC: 0.7598204922752884\n",
      "loss: 0.4864283975432901 ACC: 0.7863389487250299 AUC: 0.7857289330802991\n",
      "loss: 0.474606734864852 ACC: 0.7831170026696124 AUC: 0.7767678889641039\n",
      "loss: 0.4891859380637898 ACC: 0.7771794163674858 AUC: 0.7757402334543462\n",
      "loss: 0.46751320011475506 ACC: 0.793059007640615 AUC: 0.7896142112472045\n",
      "loss: 0.4464804337305181 ACC: 0.8071435146828685 AUC: 0.8073686875489366\n",
      "loss: 0.4812052512870115 ACC: 0.7895148669796557 AUC: 0.7841266781196845\n",
      "loss: 0.414044168065576 ACC: 0.8203995213108717 AUC: 0.8105450138132804\n",
      "loss: 0.39307671785354614 ACC: 0.8199852711037469 AUC: 0.8140993668773854\n",
      "loss: 0.3890763065394233 ACC: 0.8302494706802909 AUC: 0.8275251854260323\n",
      "loss: 0.40168678585220785 ACC: 0.8175918254625792 AUC: 0.8123321349700192\n",
      "loss: 0.3691909891717574 ACC: 0.8393629752370433 AUC: 0.8324423818247094\n",
      "loss: 0.3957938359064214 ACC: 0.8468194789652951 AUC: 0.8454832142262675\n",
      "loss: 0.37951985527487364 ACC: 0.8327349719230415 AUC: 0.8192946295829657\n",
      "loss: 0.34882711137042327 ACC: 0.8583264291632143 AUC: 0.8547620592642113\n",
      "loss: 0.35133837075794444 ACC: 0.8538617324864219 AUC: 0.8483702973082333\n",
      "loss: 0.37219247572562275 ACC: 0.8375678910061677 AUC: 0.8344239063822176\n",
      "loss: 0.37048090293126945 ACC: 0.8364632237871676 AUC: 0.8282466501261823\n",
      "loss: 0.3472518421271268 ACC: 0.8497192304151707 AUC: 0.8440806127169448\n",
      "loss: 0.33169591514503255 ACC: 0.8670256835128418 AUC: 0.8627321753130284\n",
      "loss: 0.31340140104293823 ACC: 0.8609039860075485 AUC: 0.8580076141220624\n",
      "loss: 0.3319986962220248 ACC: 0.8511460922397127 AUC: 0.8475502988803949\n",
      "loss: 0.33359895471264334 ACC: 0.8567614839362977 AUC: 0.8548783343622698\n",
      "loss: 0.31417276052867665 ACC: 0.8613182362146737 AUC: 0.8574108276468871\n",
      "loss: 0.2956256323000964 ACC: 0.8811101905550954 AUC: 0.8782066123207988\n",
      "loss: 0.30242930790957284 ACC: 0.8660590996962164 AUC: 0.8635729526220293\n",
      "loss: 0.31604626687134013 ACC: 0.8758169934640522 AUC: 0.8707100857338584\n",
      "loss: 0.30030767751090665 ACC: 0.8724109362054682 AUC: 0.8720890377318772\n",
      "loss: 0.3204904566792881 ACC: 0.8754027432569272 AUC: 0.8733728040789421\n",
      "loss: 0.29538288537193746 ACC: 0.8725029918070513 AUC: 0.8709111177906462\n",
      "loss: 0.31584593127755556 ACC: 0.8740679370339686 AUC: 0.8670221163865188\n",
      "loss: 0.2789347443510504 ACC: 0.8812022461566787 AUC: 0.8796726358096173\n",
      "loss: 0.29251040080014395 ACC: 0.8762312436711773 AUC: 0.8734352348947789\n",
      "loss: 0.3001580930808011 ACC: 0.8742520482371353 AUC: 0.8699207063711735\n",
      "loss: 0.29185331919614005 ACC: 0.8812022461566785 AUC: 0.8746092754553547\n",
      "loss: 0.28306073563940387 ACC: 0.8791309951210532 AUC: 0.8753894880488661\n",
      "loss: 0.2755170271677129 ACC: 0.8812022461566787 AUC: 0.8765627549933517\n",
      "loss: 0.28456025526804085 ACC: 0.8799594955353033 AUC: 0.877545559854549\n",
      "loss: 0.2795396105331533 ACC: 0.8817085519653872 AUC: 0.8774083886483157\n",
      "loss: 0.28129396499956355 ACC: 0.8864954432477217 AUC: 0.88040292591913\n",
      "loss: 0.2774168735041338 ACC: 0.8812943017582621 AUC: 0.8798234578831824\n",
      "loss: 0.28957543565946464 ACC: 0.8807879959495535 AUC: 0.8762084010979112\n",
      "loss: 0.25500857238383856 ACC: 0.8935376967688484 AUC: 0.8914364909246862\n",
      "loss: 0.2715176589348737 ACC: 0.8851146092239713 AUC: 0.8814787305084391\n",
      "loss: 0.251131773871534 ACC: 0.8989229494614747 AUC: 0.8962530415876823\n",
      "loss: 0.2575463389649111 ACC: 0.8908220565221395 AUC: 0.8707378535457196\n",
      "loss: 0.2511291705510196 ACC: 0.8956089478044739 AUC: 0.8916292223084094\n",
      "loss: 0.2534559579456554 ACC: 0.8953788088005156 AUC: 0.8924621144243013\n",
      "loss: 0.25702498590244965 ACC: 0.8893951946975973 AUC: 0.8869500518903689\n",
      "loss: 0.24624147288062992 ACC: 0.8976801988400995 AUC: 0.8926570811249492\n",
      "loss: 0.23224525307031238 ACC: 0.9088649544324771 AUC: 0.9049913661714264\n",
      "loss: 0.22555998756605036 ACC: 0.9015005063058088 AUC: 0.8959711334771411\n",
      "loss: 0.25925051114138437 ACC: 0.9019147565129338 AUC: 0.8983583173966395\n",
      "loss: 0.23877480100182927 ACC: 0.9063794531897266 AUC: 0.9038671866969855\n",
      "loss: 0.22060168841305902 ACC: 0.9109362054681027 AUC: 0.9097057764704874\n",
      "loss: 0.23007251366096385 ACC: 0.9055509527754761 AUC: 0.9029309242595365\n",
      "loss: 0.21830855485271006 ACC: 0.9085427598269354 AUC: 0.9064595890392304\n",
      "loss: 0.20802356741007635 ACC: 0.9154929577464789 AUC: 0.9114815414468732\n",
      "loss: 0.22033550634103663 ACC: 0.903157507134309 AUC: 0.9009424550133535\n",
      "loss: 0.21635892724289613 ACC: 0.9077142594126851 AUC: 0.9029581598375771\n",
      "loss: 0.2322329431772232 ACC: 0.9019147565129337 AUC: 0.8985170141816657\n",
      "loss: 0.21995863756712744 ACC: 0.9067937033968517 AUC: 0.9049637674805853\n",
      "loss: 0.2157278744613423 ACC: 0.9068857589984352 AUC: 0.9044950246407697\n",
      "loss: 0.18885954710490563 ACC: 0.9266777133388567 AUC: 0.9236510632114456\n",
      "loss: 0.2112480524708243 ACC: 0.9115345668783947 AUC: 0.9105739472926385\n",
      "loss: 0.22057935069589055 ACC: 0.9094633158427688 AUC: 0.9100120227887484\n",
      "loss: 0.25212740459862876 ACC: 0.8957930590076406 AUC: 0.8983509207098525\n",
      "loss: 0.2620728725896162 ACC: 0.8977722544416826 AUC: 0.8929415654105869\n",
      "loss: 0.2225697917096755 ACC: 0.8954708644020988 AUC: 0.8991419363889621\n",
      "loss: 0.23666519890813267 ACC: 0.9118567614839365 AUC: 0.9100097382888687\n",
      "loss: 0.24555948902578914 ACC: 0.9073000092055603 AUC: 0.9033361221939511\n",
      "Early stopping\n",
      "loss: 0.6415918259059682 ACC: 0.6669888612722085 AUC: 0.6531636665125699\n",
      "loss: 0.5671756372732275 ACC: 0.7294946147473074 AUC: 0.7265243182729445\n",
      "loss: 0.590082091443679 ACC: 0.7247077234649728 AUC: 0.7214088730838151\n",
      "loss: 0.5638989367905785 ACC: 0.724385528859431 AUC: 0.7115772916487524\n",
      "loss: 0.5185042567112866 ACC: 0.7450059836141029 AUC: 0.7320755671041654\n",
      "loss: 0.48341644160887776 ACC: 0.7466629844426035 AUC: 0.738174373597098\n",
      "loss: 0.46010708458283367 ACC: 0.7727607474914849 AUC: 0.7578774500082415\n",
      "loss: 0.45760341251597686 ACC: 0.7806315014268617 AUC: 0.7740114966144079\n",
      "loss: 0.4146387506933773 ACC: 0.8132652121881616 AUC: 0.8040814224071563\n",
      "loss: 0.3944369309088763 ACC: 0.8232072171591642 AUC: 0.8169793737771059\n",
      "loss: 0.3666545801302966 ACC: 0.8314922213016662 AUC: 0.8174866807011453\n",
      "loss: 0.3623136772828944 ACC: 0.840697781460002 AUC: 0.8284386819511629\n",
      "loss: 0.35298677752999696 ACC: 0.8411120316671271 AUC: 0.8365385762976172\n",
      "loss: 0.3343319971771801 ACC: 0.8522047316579213 AUC: 0.8461992089572409\n",
      "loss: 0.31848474898759055 ACC: 0.8554266777133387 AUC: 0.8488789632177561\n",
      "loss: 0.295593558865435 ACC: 0.8811101905550953 AUC: 0.8779071375078625\n",
      "loss: 0.2955472162541221 ACC: 0.8696032403571756 AUC: 0.8665780106431822\n",
      "loss: 0.32118869967320385 ACC: 0.8536315934824634 AUC: 0.8490003357215847\n",
      "loss: 0.27585465592496533 ACC: 0.884009942004971 AUC: 0.8789786661092629\n",
      "loss: 0.27663341515204487 ACC: 0.8792230507226365 AUC: 0.8763223898644515\n",
      "loss: 0.2726185672423419 ACC: 0.8807879959495536 AUC: 0.8791221073369985\n",
      "loss: 0.34126486497766834 ACC: 0.8568535395378809 AUC: 0.8446595815958716\n",
      "loss: 0.2729645327610128 ACC: 0.8878302494706803 AUC: 0.8827514410934038\n",
      "loss: 0.2449481066535501 ACC: 0.8935376967688483 AUC: 0.8905928508061349\n",
      "loss: 0.24400595268782446 ACC: 0.9056430083770598 AUC: 0.9048205610858752\n",
      "loss: 0.2271488773472169 ACC: 0.9023290067200589 AUC: 0.8998747695562678\n",
      "loss: 0.2266158856013242 ACC: 0.9044002577556846 AUC: 0.9002729077341077\n",
      "loss: 0.23162589222192764 ACC: 0.9051367025683513 AUC: 0.9007410918639238\n",
      "loss: 0.22530353595228755 ACC: 0.9015925619073921 AUC: 0.8994911621592571\n",
      "loss: 0.22317790459184086 ACC: 0.9036638129430177 AUC: 0.9006258957603549\n",
      "loss: 0.19797704127781532 ACC: 0.9204639602319801 AUC: 0.9169295489467209\n",
      "loss: 0.191184364259243 ACC: 0.9192212096106048 AUC: 0.9167836125036142\n",
      "loss: 0.20657397762817495 ACC: 0.9151707631409371 AUC: 0.9127868620448312\n",
      "loss: 0.22150126340634682 ACC: 0.9113504556752281 AUC: 0.9109602359733494\n",
      "loss: 0.19067285429028905 ACC: 0.9246985179048146 AUC: 0.921546602777231\n",
      "loss: 0.1736065429799697 ACC: 0.9238700174905643 AUC: 0.922197328907923\n",
      "loss: 0.24533358391593485 ACC: 0.8961152536131823 AUC: 0.8954541140398682\n",
      "loss: 0.22186221927404404 ACC: 0.9113504556752279 AUC: 0.911214215728463\n",
      "loss: 0.20283857338568745 ACC: 0.9136058179140203 AUC: 0.9104952645326335\n",
      "loss: 0.1909027362571043 ACC: 0.9179784589892294 AUC: 0.9150416658742458\n",
      "loss: 0.16995304296998417 ACC: 0.925204823713523 AUC: 0.9232792850282561\n",
      "loss: 0.16406920113984277 ACC: 0.9333057166528586 AUC: 0.9310859937765255\n",
      "loss: 0.16331411021597245 ACC: 0.9353769676884837 AUC: 0.9336242380751384\n",
      "loss: 0.13865873261409647 ACC: 0.9449047224523612 AUC: 0.9431753896878661\n",
      "loss: 0.17093613962916768 ACC: 0.9289330755776489 AUC: 0.9297683969203143\n",
      "loss: 0.20641961540369427 ACC: 0.9134217067108534 AUC: 0.9115696421652012\n",
      "loss: 0.1587151288986206 ACC: 0.934226272668692 AUC: 0.931559013062182\n",
      "loss: 0.14800255307379892 ACC: 0.9404400257755685 AUC: 0.9389535367522177\n",
      "loss: 0.17864388819126523 ACC: 0.9246064623032311 AUC: 0.9214411492205601\n",
      "loss: 0.16663153864005031 ACC: 0.9353769676884839 AUC: 0.9326397687501268\n",
      "loss: 0.132695511860006 ACC: 0.944904722452361 AUC: 0.9435589461767753\n",
      "loss: 0.12805157549241009 ACC: 0.9445825278468194 AUC: 0.9428083059934939\n",
      "loss: 0.17314019185655258 ACC: 0.9420049710024856 AUC: 0.9402261622983465\n",
      "loss: 0.15773488800315297 ACC: 0.9313265212188163 AUC: 0.9280525376723394\n",
      "loss: 0.14385413992054322 ACC: 0.9411764705882353 AUC: 0.9408378390447922\n",
      "loss: 0.12780903674223842 ACC: 0.9486329743164871 AUC: 0.947732211644149\n",
      "loss: 0.13616575213039622 ACC: 0.9449967780539443 AUC: 0.9394633026049504\n",
      "loss: 0.1179635853451841 ACC: 0.9569179784589894 AUC: 0.9552677642239745\n",
      "loss: 0.11650529854437884 ACC: 0.9569179784589892 AUC: 0.95553341196326\n",
      "loss: 0.10710615144275568 ACC: 0.9643744821872412 AUC: 0.9632533796829655\n",
      "loss: 0.08860779400257503 ACC: 0.9705882352941176 AUC: 0.969706471541021\n",
      "loss: 0.11207158469101962 ACC: 0.9607382859246985 AUC: 0.9563678064380293\n",
      "loss: 0.15319144742234664 ACC: 0.9366197183098591 AUC: 0.9342619752698976\n",
      "loss: 0.12506728181067636 ACC: 0.9455030838626531 AUC: 0.9430054694864701\n",
      "loss: 0.14776175392462926 ACC: 0.9482187241093619 AUC: 0.9459193082476316\n",
      "loss: 0.13486441641169436 ACC: 0.9462395286753197 AUC: 0.9421421739814884\n",
      "loss: 0.13177565353758194 ACC: 0.9469759734879868 AUC: 0.947755100323362\n",
      "loss: 0.13179159186342182 ACC: 0.9483107797109455 AUC: 0.949225393840653\n",
      "Early stopping\n",
      "loss: 0.684877847923952 ACC: 0.5721255638405597 AUC: 0.5707979116989103\n",
      "loss: 0.6039942222483018 ACC: 0.6973672097947161 AUC: 0.6851321530484281\n",
      "loss: 0.5911332894774044 ACC: 0.6886679554450889 AUC: 0.6853644208029812\n",
      "loss: 0.5525042291949777 ACC: 0.7231427782380556 AUC: 0.7161601629016549\n",
      "loss: 0.5447495404411765 ACC: 0.7146276350915952 AUC: 0.7058915519476853\n",
      "loss: 0.548943917540943 ACC: 0.7261345852895148 AUC: 0.7230428445498395\n",
      "loss: 0.5013611193965463 ACC: 0.7473994292552701 AUC: 0.7420208030335836\n",
      "loss: 0.4885961203014149 ACC: 0.7612537972935652 AUC: 0.7494341445328669\n",
      "loss: 0.5008755817132837 ACC: 0.7601031022737734 AUC: 0.7559871664053001\n",
      "loss: 0.4632438070633832 ACC: 0.7756604989413607 AUC: 0.7759524103876965\n",
      "loss: 0.46482695025556225 ACC: 0.7847740034981129 AUC: 0.7743717856697399\n",
      "loss: 0.42781583877170787 ACC: 0.8033232072171593 AUC: 0.7992403771387763\n",
      "loss: 0.4279368817806244 ACC: 0.8173156586578295 AUC: 0.8087230496400771\n",
      "loss: 0.43890923962873574 ACC: 0.8021725121973673 AUC: 0.7948997300651184\n",
      "loss: 0.41582199054605823 ACC: 0.8154285188253704 AUC: 0.804619349495491\n",
      "loss: 0.40919266728793874 ACC: 0.8109638221485778 AUC: 0.804191503401545\n",
      "loss: 0.4039684446418987 ACC: 0.8253705237963732 AUC: 0.8196195944263183\n",
      "loss: 0.3667215143933016 ACC: 0.8294209702660408 AUC: 0.8241727308721445\n",
      "loss: 0.3539489139528835 ACC: 0.8410199760655436 AUC: 0.8327160308903536\n",
      "loss: 0.36550605121780844 ACC: 0.8382122802172514 AUC: 0.8380321200078715\n",
      "loss: 0.35701361473868876 ACC: 0.8377980300101262 AUC: 0.8252340166332697\n",
      "loss: 0.354185774045832 ACC: 0.8492129246064624 AUC: 0.8428454414854806\n",
      "loss: 0.3707002331228817 ACC: 0.8348982785602503 AUC: 0.8259431588252988\n",
      "loss: 0.3553230832604801 ACC: 0.8527110374666298 AUC: 0.8491333900629924\n",
      "loss: 0.33861787704860463 ACC: 0.8542759826935469 AUC: 0.8408577587386813\n",
      "loss: 0.32932190334095673 ACC: 0.8571757341434226 AUC: 0.8496946821341158\n",
      "loss: 0.3604918183649288 ACC: 0.8490748412040873 AUC: 0.8435467878389082\n",
      "loss: 0.351279575158568 ACC: 0.8449323391328362 AUC: 0.8367910731636165\n",
      "loss: 0.3354289373930763 ACC: 0.8536315934824634 AUC: 0.8459029777768777\n",
      "loss: 0.31913909491370707 ACC: 0.8592469851790481 AUC: 0.8549544074801945\n",
      "loss: 0.3098125457763672 ACC: 0.8630672926447575 AUC: 0.8570804116168009\n",
      "loss: 0.28593744863482085 ACC: 0.8815244407622204 AUC: 0.8762934118574229\n",
      "loss: 0.2756401177714853 ACC: 0.8794531897265948 AUC: 0.8762066548143634\n",
      "loss: 0.3043746045407127 ACC: 0.8697873515603424 AUC: 0.8719872405212317\n",
      "loss: 0.2846334357472027 ACC: 0.8786246893123446 AUC: 0.8796310517814495\n",
      "loss: 0.26184004282250123 ACC: 0.8931234465617234 AUC: 0.8880241828187871\n",
      "loss: 0.2617783791878644 ACC: 0.8964374482187241 AUC: 0.8931005268337392\n",
      "loss: 0.25243421074222117 ACC: 0.8912363067292647 AUC: 0.8812879075957202\n",
      "loss: 0.25133785079507265 ACC: 0.8923870017490566 AUC: 0.8877478966034061\n",
      "loss: 0.27658644406234517 ACC: 0.8870938046580136 AUC: 0.8788339181480825\n",
      "loss: 0.26613055695505705 ACC: 0.8840099420049711 AUC: 0.8791268228357179\n",
      "loss: 0.2540963143110275 ACC: 0.894872502991807 AUC: 0.8897339695441892\n",
      "loss: 0.23913712711895213 ACC: 0.903893951946976 AUC: 0.9002807969158421\n",
      "loss: 0.24034095862332513 ACC: 0.9060572585841848 AUC: 0.9026628437741218\n",
      "loss: 0.2331126341048409 ACC: 0.9034797017398508 AUC: 0.9013808073650653\n",
      "loss: 0.25742920707253847 ACC: 0.888014360673847 AUC: 0.881534091095095\n",
      "loss: 0.27700254934675556 ACC: 0.8793151063242197 AUC: 0.8817881781700082\n",
      "loss: 0.39725203636814566 ACC: 0.8207217159164136 AUC: 0.8157385789016798\n",
      "loss: 0.2960660030298373 ACC: 0.8736536868268433 AUC: 0.8671895852720202\n",
      "loss: 0.27061453023377585 ACC: 0.882030746570929 AUC: 0.8785775819774129\n",
      "loss: 0.24540201618390925 ACC: 0.8993371996685999 AUC: 0.8946287285535914\n",
      "loss: 0.24594313870458043 ACC: 0.8998435054773083 AUC: 0.897792644454277\n",
      "Early stopping\n",
      "loss: 0.798645159777473 ACC: 0.6086256098683603 AUC: 0.6016595691541695\n",
      "loss: 0.5848922589245964 ACC: 0.6871950658197552 AUC: 0.6835499601238755\n",
      "loss: 0.558609310318442 ACC: 0.724109362054681 AUC: 0.717544530341999\n",
      "loss: 0.5473260406185599 ACC: 0.722820583632514 AUC: 0.7139040470916176\n",
      "loss: 0.5196960077566259 ACC: 0.7586762404492314 AUC: 0.7457971798698662\n",
      "loss: 0.4944322004037745 ACC: 0.777317499769861 AUC: 0.7699866312769191\n",
      "loss: 0.46672646788989797 ACC: 0.7848660590996963 AUC: 0.7794750251243134\n",
      "loss: 0.45286697324584513 ACC: 0.8062229586670349 AUC: 0.802419557947445\n",
      "loss: 0.42706578093416553 ACC: 0.8218724109362053 AUC: 0.8150985872577537\n",
      "loss: 0.4105116128921509 ACC: 0.8269354690232902 AUC: 0.8138670106938167\n",
      "loss: 0.40965625293114605 ACC: 0.8260149130074567 AUC: 0.8211180882508979\n",
      "loss: 0.39073852931751923 ACC: 0.8377059744085429 AUC: 0.8270971059579127\n",
      "loss: 0.3880216409178341 ACC: 0.8258768296050815 AUC: 0.8217545951184433\n",
      "loss: 0.3792564255349776 ACC: 0.838534474822793 AUC: 0.8350709524480029\n",
      "loss: 0.3546228040667141 ACC: 0.8493049802080457 AUC: 0.8434748194395764\n",
      "loss: 0.34503572127398324 ACC: 0.8609039860075486 AUC: 0.8584788499783099\n",
      "loss: 0.3512657617821413 ACC: 0.8494890914112121 AUC: 0.8481225418249653\n",
      "loss: 0.3489270771251005 ACC: 0.8535395378808799 AUC: 0.8503601088940396\n",
      "loss: 0.3412197460146511 ACC: 0.8530332320721716 AUC: 0.848509247806936\n",
      "loss: 0.30845921179827523 ACC: 0.8794531897265948 AUC: 0.8765618289454598\n",
      "loss: 0.32710297843989206 ACC: 0.8675319893215504 AUC: 0.8655164746630081\n",
      "loss: 0.319930754163686 ACC: 0.8655527938875079 AUC: 0.8562353746600688\n",
      "loss: 0.3013652080998701 ACC: 0.8794531897265949 AUC: 0.8757496686312345\n",
      "loss: 0.315638451015248 ACC: 0.8734235478228851 AUC: 0.8761876327264299\n",
      "loss: 0.28229419799412 ACC: 0.8886587498849307 AUC: 0.8896898607319558\n",
      "loss: 0.2916422442478292 ACC: 0.8750805486513854 AUC: 0.8750377689835445\n",
      "loss: 0.31544018317671385 ACC: 0.8659670440946332 AUC: 0.8605308798552994\n",
      "loss: 0.2688182583626579 ACC: 0.8964374482187241 AUC: 0.8931443654129687\n",
      "loss: 0.27820635543150063 ACC: 0.88617324864218 AUC: 0.8830831402799261\n",
      "loss: 0.2694653412875007 ACC: 0.8902236951118475 AUC: 0.8884218424652467\n",
      "loss: 0.2910338219474344 ACC: 0.8866795544508884 AUC: 0.8873798213752471\n",
      "loss: 0.30766063052065235 ACC: 0.8770597440854278 AUC: 0.8781627269710325\n",
      "loss: 0.2604707067503649 ACC: 0.8894872502991807 AUC: 0.886861713560641\n",
      "loss: 0.27138878755709706 ACC: 0.8841940532081378 AUC: 0.8802979259566712\n",
      "loss: 0.24040277214611278 ACC: 0.8981865046488078 AUC: 0.8932549235004958\n",
      "loss: 0.24936572067877827 ACC: 0.8937218079720151 AUC: 0.8906243029028468\n",
      "loss: 0.24307616843896754 ACC: 0.9065635643928933 AUC: 0.9017212102566081\n",
      "loss: 0.2473099599866306 ACC: 0.8986007548559332 AUC: 0.8962968329276187\n",
      "loss: 0.25704927216557893 ACC: 0.8986007548559333 AUC: 0.8954290029443355\n",
      "loss: 0.25862832060631585 ACC: 0.8980944490472245 AUC: 0.8982962974919072\n",
      "loss: 0.22133847019251654 ACC: 0.9093712602411858 AUC: 0.9079642092777623\n",
      "loss: 0.22855794342125163 ACC: 0.9047224523612263 AUC: 0.9025247193929475\n",
      "loss: 0.20181493504958994 ACC: 0.9183927091963546 AUC: 0.9152411635617954\n",
      "loss: 0.2118686656741535 ACC: 0.909785510448311 AUC: 0.9087524974442366\n",
      "loss: 0.20739005506038666 ACC: 0.9134217067108534 AUC: 0.9100336473207117\n",
      "loss: 0.19805073475136475 ACC: 0.9159992635551873 AUC: 0.9144112117564746\n",
      "loss: 0.22693961332826054 ACC: 0.8995213108717665 AUC: 0.8814951565683516\n",
      "loss: 0.2608340123997015 ACC: 0.8894872502991807 AUC: 0.8866029282550498\n",
      "loss: 0.2108293627114857 ACC: 0.9179784589892295 AUC: 0.9132285493548573\n",
      "loss: 0.19266840618322878 ACC: 0.9229494614747307 AUC: 0.921695757716299\n",
      "loss: 0.17842168623910232 ACC: 0.9295774647887325 AUC: 0.9265715518785671\n",
      "loss: 0.17308803647756577 ACC: 0.9333057166528582 AUC: 0.931992845645933\n",
      "loss: 0.1891676564426983 ACC: 0.9206480714351469 AUC: 0.9134238208285476\n",
      "loss: 0.20453410376520717 ACC: 0.9242842676976895 AUC: 0.9200028488677842\n",
      "loss: 0.16966417212696636 ACC: 0.9320629660314831 AUC: 0.9301225255706553\n",
      "loss: 0.1694872944670565 ACC: 0.930498020804566 AUC: 0.9292662141765209\n",
      "loss: 0.1852263050044284 ACC: 0.9225352112676057 AUC: 0.921959700189508\n",
      "loss: 0.16198851387290394 ACC: 0.9395194697597349 AUC: 0.937092992838013\n",
      "loss: 0.16788807840031736 ACC: 0.9328914664457333 AUC: 0.9315324046653576\n",
      "loss: 0.1809093987240511 ACC: 0.9266777133388566 AUC: 0.9258150975939413\n",
      "loss: 0.15908584173987894 ACC: 0.9382767191383595 AUC: 0.9364574627425108\n",
      "loss: 0.1567090193138403 ACC: 0.9415907207953604 AUC: 0.9398361937000408\n",
      "loss: 0.18488849348881664 ACC: 0.9197275154193134 AUC: 0.9233772919663814\n",
      "loss: 0.23867709014345617 ACC: 0.903065451532726 AUC: 0.9001245354758083\n",
      "loss: 0.1529650017619133 ACC: 0.9403479701739851 AUC: 0.9392335942882276\n",
      "loss: 0.1430473498561803 ACC: 0.9482187241093621 AUC: 0.9472367105176315\n",
      "loss: 0.14380286546314464 ACC: 0.942511276811194 AUC: 0.9412364856616137\n",
      "loss: 0.1495419453610392 ACC: 0.9457332228666115 AUC: 0.943837853138925\n",
      "loss: 0.15055010160979101 ACC: 0.9395194697597349 AUC: 0.9385210163507701\n",
      "loss: 0.13850578775300698 ACC: 0.9428334714167358 AUC: 0.9421772644314449\n",
      "loss: 0.128861364634598 ACC: 0.9511184755592381 AUC: 0.95042142714046\n",
      "loss: 0.1361378071939244 ACC: 0.9502899751449876 AUC: 0.9495106394935002\n",
      "loss: 0.19666776148711934 ACC: 0.9130995121053116 AUC: 0.9155683176043445\n",
      "loss: 0.14625324155477917 ACC: 0.9436619718309859 AUC: 0.9441112491223962\n",
      "loss: 0.1650803439757403 ACC: 0.9296695203903158 AUC: 0.9300031970288577\n",
      "loss: 0.14498853376683066 ACC: 0.9412685261898187 AUC: 0.9413807456379734\n",
      "loss: 0.1406711355289992 ACC: 0.9367117739114427 AUC: 0.9344859007701624\n",
      "loss: 0.16068066612762563 ACC: 0.9247905735063979 AUC: 0.9283892612952322\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from hgnn.load_data import load_data\n",
    "from hgnn.features import Graph_smiles\n",
    "from hgnn.trainers import train_gnn\n",
    "from hgnn.model import HGNNPredictor\n",
    "from contrast_gnns.GraphVAE import *\n",
    "from contrast_gnns.GraphTransformers import *\n",
    "from contrast_gnns.GraphSAGE import *\n",
    "from contrast_gnns.WLN import *\n",
    "from dgllife.model.model_zoo import AttentiveFPPredictor, PAGTNPredictor\n",
    "\n",
    "n_tasks=2\n",
    "n_node_feats=74\n",
    "n_edge_feats=12\n",
    "\n",
    "df = pd.read_csv(bn_train_path, header=0, sep='\\t')\n",
    "tuple_ls = list(zip(list(df['Smiles']), list(df['Label'])))\n",
    "all = load_data(tuple_ls, featurizer=Graph_smiles, if_all=all, Stratify=False, if_torch=True, batchsize=int(len(tuple_ls)/16), graph=True, drop_last=False)\n",
    "model = HGNNPredictor(\n",
    "                    node_gat = True, \n",
    "                    edge_gat = True, \n",
    "                    weave = True, \n",
    "                    mpnn = True, \n",
    "                    n_node_feats=n_node_feats, n_edge_feats=n_edge_feats, num_layers=2, n_heads=5, n_hidden_feats=100, activation=F.relu, attn_activation=nn.LeakyReLU(negative_slope=0.2), attn_dropout=0, feat_dropout=0, xavier_normal=False, n_tasks=n_tasks,\n",
    "                    )\n",
    "rst = train_gnn.train_bi_classify_all(model, all=all, edge=True, max_epochs=500, patience=7, save_folder=PWD+'/pretrained/',save_name='bn_hgnn.pth')\n",
    "\n",
    "# other 5 models\n",
    "model = WLNPredictor(node_in_feats=n_node_feats, edge_in_feats=n_edge_feats, node_out_feats=100, n_layers=2, project_in_feats=True, set_comparison=True, n_tasks=n_tasks)\n",
    "rst = train_gnn.train_bi_classify_all(model, all=all, edge=True, max_epochs=500, patience=7, save_folder=PWD+'/pretrained/',save_name='bn_wln.pth')\n",
    "\n",
    "model = AttentiveFPPredictor(node_feat_size=n_node_feats,edge_feat_size=n_edge_feats,num_layers=2,num_timesteps=2,graph_feat_size=100,n_tasks=n_tasks,dropout=0.) \n",
    "rst = train_gnn.train_bi_classify_all(model, all=all, edge=True, max_epochs=500, patience=7, save_folder=PWD+'/pretrained/',save_name='bn_afp.pth')\n",
    "\n",
    "model = GraphSAGEPredictor(in_feats=n_node_feats, hidden_feats=[100,100], activation=None, dropout=None, aggregator_type=None, n_tasks=n_tasks)\n",
    "rst = train_gnn.train_bi_classify_all(model, all=all, edge=False, max_epochs=500, patience=7, save_folder=PWD+'/pretrained/',save_name='bn_gsage.pth')\n",
    "\n",
    "\n",
    "\n",
    "####\n",
    "df = pd.read_csv(bs_train_path, header=0, sep='\\t')\n",
    "tuple_ls = list(zip(list(df['Smiles']), list(df['Label'])))\n",
    "all = load_data(tuple_ls, featurizer=Graph_smiles, if_all=all, Stratify=False, if_torch=True, batchsize=int(len(tuple_ls)/16), graph=True, drop_last=False)\n",
    "model = HGNNPredictor(\n",
    "                    node_gat = True, \n",
    "                    edge_gat = True, \n",
    "                    weave = True, \n",
    "                    mpnn = True, \n",
    "                    n_node_feats=n_node_feats, n_edge_feats=n_edge_feats, num_layers=2, n_heads=5, n_hidden_feats=100, activation=F.relu, attn_activation=nn.LeakyReLU(negative_slope=0.2), attn_dropout=0, feat_dropout=0, xavier_normal=False, n_tasks=n_tasks,\n",
    "                    )\n",
    "rst = train_gnn.train_bi_classify_all(model, all=all, edge=True, max_epochs=500, patience=7, save_folder=PWD+'/pretrained/',save_name='bs_hgnn.pth')\n",
    "\n",
    "# other 5 models\n",
    "model = WLNPredictor(node_in_feats=n_node_feats, edge_in_feats=n_edge_feats, node_out_feats=100, n_layers=2, project_in_feats=True, set_comparison=True, n_tasks=n_tasks)\n",
    "rst = train_gnn.train_bi_classify_all(model, all=all, edge=True, max_epochs=500, patience=7, save_folder=PWD+'/pretrained/',save_name='bs_wln.pth')\n",
    "\n",
    "model = AttentiveFPPredictor(node_feat_size=n_node_feats,edge_feat_size=n_edge_feats,num_layers=2,num_timesteps=2,graph_feat_size=100,n_tasks=n_tasks,dropout=0.) \n",
    "rst = train_gnn.train_bi_classify_all(model, all=all, edge=True, max_epochs=500, patience=7, save_folder=PWD+'/pretrained/',save_name='bs_afp.pth')\n",
    "\n",
    "model = GraphSAGEPredictor(in_feats=n_node_feats, hidden_feats=[100,100], activation=None, dropout=None, aggregator_type=None, n_tasks=n_tasks)\n",
    "rst = train_gnn.train_bi_classify_all(model, all=all, edge=False, max_epochs=500, patience=7, save_folder=PWD+'/pretrained/',save_name='bs_gsage.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor Comparision on Bitter/Non-Bitter test dataset\n",
    "+ CNN (https://www.sciencedirect.com/science/article/pii/S096399692200031X#f0005)\n",
    "+ descriptor MLP (https://www.sciencedirect.com/science/article/pii/S096399692200031X#f0005)\n",
    "+ RDKFP MLP (https://www.sciencedirect.com/science/article/pii/S096399692200031X#f0005)\n",
    "+ BitterPredict (https://www.nature.com/articles/s41598-017-12359-7)\n",
    "+ BitterX (https://mdl.shsmu.edu.cn/BitterX)\n",
    "+ BitterSweetForest/VirtualTaste (https://insilico-cyp.charite.de/VirtualTaste/)\n",
    "+ HGNN\n",
    "+ WLN\n",
    "+ AttentiveFP\n",
    "+ GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contrast_predictors.BitterPredict import *\n",
    "from hgnn.utils import bi_classify_metrics\n",
    "\n",
    "qikprop_filepath = os.path.join(PWD+\"/dataset/taste_dataset/qikprop.CSV\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN for Bitter/Non-bitter:\n",
      "[133.          30.          33.          82.           0.713\n",
      "   0.816        0.732        0.773        0.64075473   0.722\n",
      "   0.53116658   0.7644972 ]\n",
      "MLP with Descriptors as input for Bitter/Non-bitter:\n",
      "[128.          35.          28.          87.           0.757\n",
      "   0.785        0.713        0.773        0.64020624   0.734\n",
      "   0.53769718   0.77089891]\n",
      "MLP with RDKFP as input for Bitter/Non-bitter:\n",
      "[150.          13.          22.          93.           0.809\n",
      "   0.92         0.877        0.874        0.78865269   0.842\n",
      "   0.73912514   0.86447053]\n",
      "BitterPredict based on Adaboost for Bitter/Non-bitter:\n",
      "[133.          30.          32.          83.           0.722\n",
      "   0.816        0.735        0.777        0.64523489   0.728\n",
      "   0.53913004   0.76884503]\n",
      "VisualTaste/BitterSweetForest based on RandomForest for Bitter/Non-bitter:\n",
      "[95.         68.         20.         95.          0.826       0.583\n",
      "  0.583       0.683       0.55340417  0.683       0.40890904  0.70445452]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hy/Softwares/Program/miniconda3/envs/ml/lib/python3.8/site-packages/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HGNN for Bitter/Non-bitter:\n",
      "[145.          18.          26.          89.           0.774\n",
      "   0.89         0.832        0.842        0.73724724   0.802\n",
      "   0.67155714   0.8317418 ]\n",
      "WLN for Bitter/Non-bitter:\n",
      "[146.          17.          23.          92.           0.8\n",
      "   0.896        0.844        0.856        0.75796317   0.821\n",
      "   0.7017971    0.84785276]\n",
      "AFP for Bitter/Non-bitter:\n",
      "[153.          10.          24.          91.           0.791\n",
      "   0.939        0.901        0.878        0.79928832   0.842\n",
      "   0.74746573   0.86497733]\n",
      "GSAGE for Bitter/Non-bitter:\n",
      "[133.          30.          17.          98.           0.852\n",
      "   0.816        0.766        0.831        0.71359673   0.807\n",
      "   0.66016078   0.83406242]\n"
     ]
    }
   ],
   "source": [
    "bn_rsts = []\n",
    "\n",
    "model = BoCNN()\n",
    "bn_test_imgs_dir = os.path.join(PWD, 'dataset/taste_dataset/bitter_nonbitter/bn_test_imgs/') \n",
    "if not os.path.exists(bn_test_imgs_dir):\n",
    "    os.mkdir(bn_test_imgs_dir)\n",
    "bn_cnn_train = cnn_prepare(bn_test, bn_test_imgs_dir, data_aug=False)\n",
    "test = all_batchsize(bn_cnn_train, 10000)\n",
    "rst = train_mlp_cnn.test_bi_classify(model, test=test, plot_cm=True, save_path=PWD+'/pretrained/bn_cnn.pth',classnames=['Non-bitter','Bitter'])\n",
    "print(\"CNN for Bitter/Non-bitter:\")\n",
    "print(rst)\n",
    "bn_rsts.append(rst)\n",
    "\n",
    "bn_ds_mlp_test = Descriptors_bitter_nonbitter(bn_test)\n",
    "test = all_batchsize(bn_ds_mlp_test, 10000)\n",
    "model = BoMLP(n_feats=21)\n",
    "rst =  train_mlp_cnn.test_bi_classify(model, test=test, plot_cm=True, save_path=PWD+'/pretrained/bn_ds_mlp.pth',classnames=['Non-bitter','Bitter'])\n",
    "print(\"MLP with Descriptors as input for Bitter/Non-bitter:\")\n",
    "print(rst)\n",
    "bn_rsts.append(rst)\n",
    "\n",
    "bn_rdkfp_mlp_test = RDKFP(bn_test)\n",
    "test = all_batchsize(bn_rdkfp_mlp_test, 10000)\n",
    "model = BoMLP(n_feats=2048)\n",
    "rst =  train_mlp_cnn.test_bi_classify(model, test=test, plot_cm=True, save_path=PWD+'/pretrained/bn_rdkfp_mlp.pth',classnames=['Non-bitter','Bitter'])\n",
    "print(\"MLP with RDKFP as input for Bitter/Non-bitter:\")\n",
    "print(rst)\n",
    "bn_rsts.append(rst)\n",
    "\n",
    "trues,preds = AdaBoost.test(index_filepath=bn_test_path, qikprop_filepath=qikprop_filepath, save_name=\"bn_Adaboost\")\n",
    "rst = bi_classify_metrics(trues,preds,plot_cm=True,save_path=PWD+\"/pretrained/bn_Adaboost.png\", classnames=['Non-bitter','Bitter'])\n",
    "print(\"BitterPredict based on Adaboost for Bitter/Non-bitter:\")\n",
    "print(rst)\n",
    "bn_rsts.append(rst)\n",
    "\n",
    "from contrast_predictors.VirtualTaste import get_virtual_taste_result\n",
    "preds = get_virtual_taste_result()\n",
    "trues = list(pd.read_csv(bn_test_path, sep=\"\\t\",header=0)['Label'])\n",
    "rst = bi_classify_metrics(np.array(trues), preds)\n",
    "print(\"VisualTaste/BitterSweetForest based on RandomForest for Bitter/Non-bitter:\")\n",
    "print(rst)\n",
    "bn_rsts.append(rst)\n",
    "\n",
    "\n",
    "\n",
    "from hgnn.utils import simple_classify_metrics\n",
    "from contrast_predictors.BitterX import get_result\n",
    "preds = get_result()\n",
    "trues = list(pd.read_csv(bn_test_path, sep=\"\\t\",header=0)['Label'])\n",
    "rst = simple_classify_metrics(trues, preds)\n",
    "print(\"BitterX for Bitter/Non-bitter:\")\n",
    "print(rst)\n",
    "bn_rsts.append(rst)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(bn_test_path, header=0, sep='\\t')\n",
    "tuple_ls = list(zip(list(df['Smiles']), list(df['Label'])))\n",
    "test = load_data(tuple_ls, featurizer=Graph_smiles, if_all=all, Stratify=False, if_torch=True, batchsize=10000, graph=True, drop_last=False)\n",
    "model = HGNNPredictor(\n",
    "                    node_gat = True, \n",
    "                    edge_gat = True, \n",
    "                    weave = True, \n",
    "                    mpnn = True, \n",
    "                    n_node_feats=n_node_feats, n_edge_feats=n_edge_feats, num_layers=2, n_heads=5, n_hidden_feats=100, activation=F.relu, attn_activation=nn.LeakyReLU(negative_slope=0.2), attn_dropout=0, feat_dropout=0, xavier_normal=False, n_tasks=n_tasks,\n",
    "                    )\n",
    "rst = train_gnn.test_bi_classify(model, test=test, edge=True, save_path=PWD+'/pretrained/bn_hgnn.pth',classnames=['Non-bitter','Bitter'])\n",
    "print(\"HGNN for Bitter/Non-bitter:\")\n",
    "print(rst)\n",
    "bn_rsts.append(rst)\n",
    "\n",
    "model = WLNPredictor(node_in_feats=n_node_feats, edge_in_feats=n_edge_feats, node_out_feats=100, n_layers=2, project_in_feats=True, set_comparison=True, n_tasks=n_tasks)\n",
    "rst = train_gnn.test_bi_classify(model, test=test, edge=True, save_path=PWD+'/pretrained/bn_wln.pth',classnames=['Non-bitter','Bitter'])\n",
    "print(\"WLN for Bitter/Non-bitter:\")\n",
    "print(rst)\n",
    "bn_rsts.append(rst)\n",
    "\n",
    "model = AttentiveFPPredictor(node_feat_size=n_node_feats,edge_feat_size=n_edge_feats,num_layers=2,num_timesteps=2,graph_feat_size=100,n_tasks=n_tasks,dropout=0.) \n",
    "rst = train_gnn.test_bi_classify(model, test=test, edge=True, save_path=PWD+'/pretrained/bn_afp.pth',classnames=['Non-bitter','Bitter'])\n",
    "print(\"AFP for Bitter/Non-bitter:\")\n",
    "print(rst)\n",
    "bn_rsts.append(rst)\n",
    "\n",
    "model = GraphSAGEPredictor(in_feats=n_node_feats, hidden_feats=[100,100], activation=None, dropout=None, aggregator_type=None, n_tasks=n_tasks)\n",
    "rst = train_gnn.test_bi_classify(model, test=test, edge=False, save_path=PWD+'/pretrained/bn_gsage.pth',classnames=['Non-bitter','Bitter'])\n",
    "print(\"GSAGE for Bitter/Non-bitter:\")\n",
    "print(rst)\n",
    "bn_rsts.append(rst)\n",
    "\n",
    "np.savetxt(PWD+\"/results/compare_predictor/bitter_nonbitter\" , bn_rsts, fmt='%.2f')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor Comparision on Bitter/Sweet test dataset\n",
    "+ CNN (https://www.sciencedirect.com/science/article/pii/S096399692200031X#f0005)\n",
    "+ descriptor MLP (https://www.sciencedirect.com/science/article/pii/S096399692200031X#f0005)\n",
    "+ RDKFP MLP (https://www.sciencedirect.com/science/article/pii/S096399692200031X#f0005)\n",
    "+ HGNN\n",
    "+ WLN\n",
    "+ AttentiveFP\n",
    "+ GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN for Bitter/Sweet:\n",
      "[121.          18.          31.          84.           0.73\n",
      "   0.871        0.824        0.807        0.72358177   0.774\n",
      "   0.61018901   0.80046919]\n",
      "MLP with Descriptors as input for Bitter/Sweet:\n",
      "[88.         51.         25.         90.          0.783       0.633\n",
      "  0.638       0.701       0.59796266  0.703       0.41638002  0.70785111]\n",
      "MLP with RDKFP as input for Bitter/Sweet:\n",
      "[124.          15.          22.          93.           0.809\n",
      "   0.892        0.861        0.854        0.78299098   0.834\n",
      "   0.7055876    0.85039099]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hy/Softwares/Program/miniconda3/envs/ml/lib/python3.8/site-packages/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HGNN for Bitter/Sweet:\n",
      "[126.          13.          18.          97.           0.843\n",
      "   0.906        0.882        0.878        0.81466061   0.862\n",
      "   0.75337781   0.87497654]\n",
      "WLN for Bitter/Sweet:\n",
      "[125.          14.          20.          95.           0.826\n",
      "   0.899        0.872        0.866        0.7987242    0.848\n",
      "   0.72948637   0.86268377]\n",
      "AFP for Bitter/Sweet:\n",
      "[133.           6.          35.          80.           0.696\n",
      "   0.957        0.93         0.839        0.78491358   0.796\n",
      "   0.686316     0.82624335]\n",
      "GSAGE for Bitter/Sweet:\n",
      "[124.          15.          18.          97.           0.843\n",
      "   0.892        0.866        0.87         0.80137856   0.854\n",
      "   0.73743535   0.8677823 ]\n"
     ]
    }
   ],
   "source": [
    "bs_rsts = []\n",
    "\n",
    "model = BoCNN()\n",
    "bs_test_imgs_dir = os.path.join(PWD, 'dataset/taste_dataset/bitter_sweet/bs_test_imgs/') \n",
    "if not os.path.exists(bs_test_imgs_dir):\n",
    "    os.mkdir(bs_test_imgs_dir)\n",
    "bs_cnn_train = cnn_prepare(bs_test, bs_test_imgs_dir, data_aug=False)\n",
    "test = all_batchsize(bs_cnn_train, 10000)\n",
    "rst = train_mlp_cnn.test_bi_classify(model, test=test, plot_cm=True, save_path=PWD+'/pretrained/bs_cnn.pth',classnames=['Sweet','Bitter'])\n",
    "print(\"CNN for Bitter/Sweet:\")\n",
    "print(rst)\n",
    "bs_rsts.append(rst)\n",
    "\n",
    "bs_ds_mlp_test = Descriptors_bitter_sweet(bs_test)\n",
    "test = all_batchsize(bs_ds_mlp_test, 10000)\n",
    "model = BoMLP(n_feats=17)\n",
    "rst = train_mlp_cnn.test_bi_classify(model, test=test, plot_cm=True, save_path=PWD+'/pretrained/bs_ds_mlp.pth',classnames=['Sweet','Bitter'])\n",
    "print(\"MLP with Descriptors as input for Bitter/Sweet:\")\n",
    "print(rst)\n",
    "bs_rsts.append(rst)\n",
    "\n",
    "bs_rdkfp_mlp_test = RDKFP(bs_test)\n",
    "test = all_batchsize(bs_rdkfp_mlp_test, 10000)\n",
    "model = BoMLP(n_feats=2048)\n",
    "rst = train_mlp_cnn.test_bi_classify(model, test=test, plot_cm=True, save_path=PWD+'/pretrained/bs_rdkfp_mlp.pth',classnames=['Sweet','Bitter'])\n",
    "print(\"MLP with RDKFP as input for Bitter/Sweet:\")\n",
    "print(rst)\n",
    "bs_rsts.append(rst)\n",
    "\n",
    "df = pd.read_csv(bs_test_path, header=0, sep='\\t')\n",
    "tuple_ls = list(zip(list(df['Smiles']), list(df['Label'])))\n",
    "test = load_data(tuple_ls, featurizer=Graph_smiles, if_all=all, Stratify=False, if_torch=True, batchsize=10000, graph=True, drop_last=False)\n",
    "model = HGNNPredictor(\n",
    "                    node_gat = True, \n",
    "                    edge_gat = True, \n",
    "                    weave = True, \n",
    "                    mpnn = True, \n",
    "                    n_node_feats=n_node_feats, n_edge_feats=n_edge_feats, num_layers=2, n_heads=5, n_hidden_feats=100, activation=F.relu, attn_activation=nn.LeakyReLU(negative_slope=0.2), attn_dropout=0, feat_dropout=0, xavier_normal=False, n_tasks=n_tasks,\n",
    "                    )\n",
    "rst = train_gnn.test_bi_classify(model, test=test, edge=True, save_path=PWD+'/pretrained/bs_hgnn.pth',classnames=['Sweet','Bitter'])\n",
    "print(\"HGNN for Bitter/Sweet:\")\n",
    "print(rst)\n",
    "bs_rsts.append(rst)\n",
    "\n",
    "# other 5 models\n",
    "model = WLNPredictor(node_in_feats=n_node_feats, edge_in_feats=n_edge_feats, node_out_feats=100, n_layers=2, project_in_feats=True, set_comparison=True, n_tasks=n_tasks)\n",
    "rst = train_gnn.test_bi_classify(model, test=test, edge=True, save_path=PWD+'/pretrained/bs_wln.pth',classnames=['Sweet','Bitter'])\n",
    "print(\"WLN for Bitter/Sweet:\")\n",
    "print(rst)\n",
    "bs_rsts.append(rst)\n",
    "\n",
    "model = AttentiveFPPredictor(node_feat_size=n_node_feats,edge_feat_size=n_edge_feats,num_layers=2,num_timesteps=2,graph_feat_size=100,n_tasks=n_tasks,dropout=0.) \n",
    "rst = train_gnn.test_bi_classify(model, test=test, edge=True, save_path=PWD+'/pretrained/bs_afp.pth',classnames=['Sweet','Bitter'])\n",
    "print(\"AFP for Bitter/Sweet:\")\n",
    "print(rst)\n",
    "bs_rsts.append(rst)\n",
    "\n",
    "model = GraphSAGEPredictor(in_feats=n_node_feats, hidden_feats=[100,100], activation=None, dropout=None, aggregator_type=None, n_tasks=n_tasks)\n",
    "rst = train_gnn.test_bi_classify(model, test=test, edge=False, save_path=PWD+'/pretrained/bs_gsage.pth',classnames=['Sweet','Bitter'])\n",
    "print(\"GSAGE for Bitter/Sweet:\")\n",
    "print(rst)\n",
    "bs_rsts.append(rst)\n",
    "\n",
    "\n",
    "np.savetxt(PWD+\"/results/compare_predictor/bitter_sweet\" , bs_rsts, fmt='%.2f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
